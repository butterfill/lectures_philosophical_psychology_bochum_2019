---cson
layout: 'deck_unit'
title: "The Teleological Stance"
tags: []
description: """
  The Teleological Stance (Gergeley and Csibra , 1995) provides a computational
  theory of pure goal ascription.
  Pure goal ascription is the process of identifying goals to which anothers’
  actions are directed independently of any knowledge, or beliefs about,
  the intentions or other mental states of an agent.
  """
---

include ../../../fragments/unit_mixins










//- +slide({bkg:'behaviour_reading_25.jpg'})
//-   .notes: :t
//-     In the lecture on behaviour reading last week, I offered a brief survey 
//-     of mechanisms that could be involved in getting from joint displacements and
//-     bodily configurations to larger, more abstract bits of behaviour grouped into
//-     units in ways that reflect structures of action.

//- first pass ...

+slide_rh_white({step:true})
  .teleological.hide
    +run_across
      p.center
        span The ‘Teleological Stance’
        br
        span(style='mix-blend-mode:difference') ~ The goals of an action are those outcomes which the means is a best available way of bringing about.
    p.right.invert Csibra & Gergely
    
  +left_half
    p.center.invert Planning
    p.hem-around 1. This outcome, G, is the goal (specification)
    p.hem-around 2. Means m is a best available
       span.star *
       span  way of bringing G about
    p.hem-above 3. ∴ adopt m
  +right_half({step:true})
    p.center.noinvert Tracking
    p.hem-around.one 1. This means, m, has been adopted (observation)
    p.hem-around.two 2. G is an outcome such that: m is a best available
      span.star *
      span  way of bringing G about
    p.hem-above 3. ∴ G is a goal of the observed action
    .notes: :t
      So planning is the process of moving from goals to means,
      whereas tracking goes in the reverse direction, from means to goals.
      But what is common to the two is the relation between means and goals.
      In both cases, planning and goal-tracking, the means that are adopted should be a best available
      way of bringing the goal about.
  .slide
    +invert('.star')
  .slide
    +uninvert('.star')
    +show('.teleological', 0)
    .notes: :t
      Note that this is not exactly an answer to our question,
      How can infants track goals from nine months of age (or earlier)?
      It provides what Marr would call a computational description.
    .notes: :t
      That is, it provides a function
      from 
      facts about events and states of affairs that could be known without knowing which goals any
      particular actions are directed to, nor any facts about particular mental states
      to 
      one or more outcomes which are the goals of an action.
    .notes: :t
      Providing this function explains how pure goal-tracking is possible in principle.
    .notes: :t
      But what we want to know, of course, is how infants (and adults) actually compute this function.
      If this is (roughly) the function which computationally describes pure goal tracking,
      what are the representations and processes involved in pure goal tracking?
  .slide
    +hide('.left-half')
    //-   +highlight-row('.one')
    //-   .notes: :t
    //-     We need to know how they identify means from observing joint displacements and bodily movements ...
    //- .slide
    //-   +unhighlight-row('.one')
    +highlight-row('.two')
    .notes: :t
      An we need to know how they compute to which outcome a means is the best available.

//- closer look



section.slide
  .words: .container_12
    .grid_3
      p.quote.notes.handout.show(style='border-right:1px grey dashed;padding-right:9px;margin-right:-9px')
        span ‘an action can be explained by a goal state if, and only if, it is 
        span.seen-as seen as 
        span  the 
        span.most-justifiable 
          span.most most
          span  justifiable action 
        span towards that 
        span goal state that is available within the constraints of reality’
      .notes.handout.ctd \citep[p.~255]{Csibra:1998cx}
      p.quote.right.grey-text Csibra & Gergely (1998, 255)
    .slide
      +highlight('.most-justifiable')
    .slide
      .grid_9
        p.step1.hide 1. action a is directed to some goal;
        p.step2.hide  2. actions of a’s type are 
          span.normally normally
          span  means of realising outcomes of G’s type;
        p.step3.hide 3. no available alternative action is a significantly  
          span.better better*
          span  means of realising outcome G;
        p.step4.hide 4. the occurrence of outcome G is  
          span.desirable desirable
          span ;
        p.step5.hide 5. there is no other outcome, G′, the occurrence of which would be at least comparably desirable and where (2) and (3) both hold of G′ and a
        p.step6.hide Therefore:
        p.step7 6. 
          span.g G
          span   is a goal to which action 
          span.a a
          span   is directed.
      .slide
        +invert('.step7 .g')
      .slide
        +uninvert('.step7 .g')
        +invert('.step7 .a')
      .slide
        +uninvert('.step7 .a')
      .slide
        +show('.step1')
        .notes: :t
          We start with the assumption that we know the event is an action.
      .slide
        +show('.step2')
      .slide
        +unhighlight('.most-justifiable')
        +invert('.normally')
      .slide
        +invert('.seen-as')
        .notes: :t
          Why normally? Because of the ‘seen as’.
      .slide
        +uninvert('.normally')
        +uninvert('.seen-as')
      .slide
        +invert('.most')
      .slide
        +show('.step3')
      .slide
        +uninvert('.most')
      .slide
        +blur('.quote')
        +show('.step6')
        .notes: :t
          Any objections?
        .notes: :t
          I have an objection.
          Consider a case in which I perform an action directed to 
          the outcome of pouring some hot tea into a mug.
          Could this pattern of inference imply that the outcome be the goal of my action?
          Only if it also implies that moving my elbow is a goal of my action
          as well.
          And pouring some liquid. 
          And moving air in a certain way.
          And ...
        .notes: :t
          How can we avoid this objection?
      .slide
        +show('.step4')
      .slide
        +highlight('.desirable')
        .notes: :t
          Doesn’t this conflict with the aim of explaining *pure* behaviour reading?
          Not if desirable is understood as something objective.
          [explain]
      .slide
        +unhighlight('.desirable')
        .notes: :t
          Now we are almost done, I think.
      .slide
        +show('.step5')
      .slide
        +unblur('.quote')
        .notes: :t
          OK, I think this is reasonably true to the quote.
          So we’ve understood the claim.
          But is it true?
      .slide
        +blur('.quote')
        +invert('.better')
        .notes: :t
          How good is the agent at optimising the selection of means to her goals?
          And how good is the observer at identifying the optimality of means in relation to outcomes?
          \textbf{
          For optimally correct goal ascription, we want there to be a match between
          (i) how well the agent can optimise her choice of means
          and
          (i) how well the observer can detect such optimality.}
          Failing such a match, the inference will not result in correct goal ascription.
        .notes: :t
          But I don’t think this is an objection to the Teleological Stance as a
          computational theory of pure goal ascription.  It is rather a detail
          which concerns the next level, the level of representations and algorithms.
          The computational theory imposes demands at the next level.
        .handout: :t
          ‘Such calculations require detailed knowledge of biomechanical factors that 
          determine the motion capabilities and energy expenditure of agents. However, 
          in the absence of such knowledge, one can appeal to heuristics that approximate 
          the results of these calculations on the basis of knowledge in other domains 
          that is certainly available to young infants. For example, the length of 
          pathways can be assessed by geometrical calculations, taking also into 
          account some physical factors (like the impenetrability of solid objects). 
          Similarly, the fewer steps an action sequence takes, the less effort it might 
          require, and so infants’ numerical competence can also contribute to efficiency 
          evaluation.’ \citep{csibra:2013_teleological}
      .slide
        +uninvert('.better')
        .notes: :t
          So this is the teleological stance, a computational description
          of goal ascription.
        .notes: :t
          Although this is rarely noted, 
          I think the Teleological Stance takes us beyond Dennett’s intentional stance 
          because it allows us to distinguish between people on the basis of what
          they do.
          You reach for the red box; your goal is to retrieve the food.
          I reach for the blue box, so my goal is to retrieve the poison.
        .notes: :t
          But there is a problem for the Teleological Stance ...
          
+slide_middle
  p.center How is this computed?