---cson
layout: 'deck_unit'
title: "Appendix: Representational Format"
tags: []
description: """
  
  """
---

include ../../../fragments/unit_mixins


+slide_middle({bkg:'intention_and_motor_representation/Slide25.jpg'})
  .notes: :t
    As background we first need a generic distinction between content and format. 
    Imagine you are in an unfamiliar city and are trying to get to the central station. 
    A stranger offers you two routes. Each route could be represented by a distinct line 
    on a paper map. The difference between the two lines is a difference in content. 
    
+slide_middle({bkg:'intention_and_motor_representation/Slide26.jpg'})
  .notes: :t
    Each of the routes could alternatively have been represented by a distinct series 
    of instructions written on the same piece of paper; these cartographic and 
    propositional representations differ in format. The format of a representation 
    constrains its possible contents. For example, a representation with a cartographic 
    format cannot represent what is represented by sentences such as `There could not be a 
    mountain whose summit is inaccessible.'\footnote{ Note that the distinction between 
    content and format is orthogonal to issues about representational medium. The maps in 
    our illustration may be paper map or electronic maps, and the instructions may be spoken, 
    signed or written. This difference is one of medium.} The distinction between content and 
    format is necessary because, as our illustration shows, each can be varied independently 
    of the other.
    
+slide_middle({bkg:'intention_and_motor_representation/Slide27.jpg'})
  .notes: :t
    Format matters because only where two representations have the same format can they be straightforwardly inferentially integrated.
  .notes: :t
    To illustrate, let’s stay with representations of routes.  
    Suppose you are given some verbal instructions describing a route. You are then shown a representation of a route on a map and asked whether this is the same route that was verbally described. You are not allowed to find out by following the routes or by imagining following them. 
    Special cases aside, answering the question will involve a process of translation because two distinct representational formats are involved, propositional and cartographic. It is not be enough that you could follow either representation of the route. You will also need to be able to translate from at least one representational format into at least one other format. 

+slide_middle
  .notes: :t
    Think of predictive coding.
    Think of CTM.
    Think of any account of the mind you like.
    I bet that the only way that non-accidental matches can occur 
    on the account is through a process of inference.
  p Differences in representational format
  p block inferential integration 
  p (without 
    span.translation translation
    span ),
  p and so create interface problems.
  .slide
    +invert('.translation')
    .notes: :t
      \citet[p.~2]{jackendoff:1996_architecture} proposes 
      ‘a systemof interface modules. An interface module communicates between two
      levels of encoding, say Ll and L2, by carrying a partial translation of information 
      in Ll form into information in L2 form.’
    .notes: :t
      Translation might work in some cases
      (maybe between phonology and syntax,
      or between spatial and linguistic representation?).
      But it does not appear to work for motivational states,
      and I guess not for executive (Bach: effective) states either.
  .slide
    +uninvert('.translation')
    .notes: :t
      The mind is made up of lots of different, loosely
      connected systems that work largely independently of each other. To a certain extent it’s fine for
      them to go their own way; and of course since they all get the same inputs (what with being parts of
      a single subject), there are limits on how separate the ways the go can be. Still, it’s often good
      for them to be aligned, at least eventually.
    .notes: :t
      But how are they ever nonaccidentally brought into alignment?
  .slide
    p.em-above One function of  
      span.experience experience
    p is to solve these problems.
    .slide
      +invert('.experience')
      .notes: :t
        Experience is what enables there to be nonaccidental eventual alignment of largely independent
        cognitive systems. This is what experience is for.
      .notes: :t
        Can we think along these lines in the case of action?
      .notes: :t
        This was clear enough in Dickinson’s case. 
        But how could it work in the case intention vs motor representation?
      .notes: :t
        Two complications make it appear difficlut ..
