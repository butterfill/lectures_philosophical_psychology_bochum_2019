---
layout: 'deck_unit'
title: "Solidity & Momentum"
tags: []
description: ""
---

include ../../../fragments/unit_mixins





+slide_middle
  p.center incorporeal
  p.center (no perceptual experience of force)

+slide_middle
  p.center object indexes

+slide
  .notes: :t()
    (from figure caption): ' A number (here eight) of identical objects are shown (at t = 1), 
    and a subset (the `targets') is selected by, say,  ̄ashing them (at t 􏰈 2), after which 
    the objects move in unpredictable ways (with or without self-occlusion) for about 10 s. 
    At the end of the trial the observer has to either pick out all the targets using a 
    pointing device or judge whether one that is selected by the experimenter (e.g. by 
     ̄ashing it, as shown at t 􏰈 4) is a target.' \citep[p.\ 142]{Pylyshyn:2001hl}
  .notes: :t()
    Highlight the case where subject is asked whether this is one of the objects identified.
    (If a target disappears, subjects can also say where it was and which direction it was 
    moving in.)
  .notes The limit of 3, maybe 4, objects will be important later.
  +img_clip('pylyshyn_2001_fig6.png','rect(0, 200px, 300px, 0)')
  .kludge(style='margin-top:300px;') &nbsp;
  +clip('img:eq(0)','rect(0, 370px, 300px, 0)')
  +clip('img:eq(0)','rect(0, 530px, 300px, 0)')
  +clip('img:eq(0)','auto')
  p.source Pylyshyn 2001, figure 6
  .notes What does this tell us?
  .notes If attention is organised around objects, the perceptual system must be capable of identifying and tracking objects.
  .slide
    p.center object index
    .notes.handout: :t()
      Leslie et al say an object index is ‘a mental token that functions as a pointer to an 
      object’ \citep[p.\ 11]{Leslie:1998zk}
    .notes.handout: :t()
      ‘Pylyshyn’s FINST model: you have four or five indexes which can be attached to objects; 
      it’s a bit like having your fingers on an object: you might not know anything about the 
      object, but you can say where it is relative to the other objects you’re fingering. 
      (ms. 19-20)’ \citep{Scholl:1999mi}

+slide_middle
  p.center object specific preview benefit
                        
+slide
  .notes Background: object specific preview benefit
  .notes We can measure object indexes using the object specific preview benefit.
  .notes.handout  The \emph{object specific preview benefit}: ‘observers can identify target letters that matched the preview letter from the same object faster than they can identify target letters that matched the preview letter from the other object.’ 
  .notes.handout.ctd \citep[p.\ 2]{Krushke:1996ge}
  +img_clip('kahneman_1992_fig3.png','rect(5px,175px, 600px, 0)')
  +clip('img:eq(0)','rect(5px,315px, 600px, 0)')
  +clip('img:eq(0)','auto')
  p.source Kahneman et al 1992, figure 3

+slide_middle
  p.center How are object indexes updated from partial information?
  
+slide_middle
  p hypothesis
  p.em-above: :t()
    There is a system of object indexes for tracking objects’ movements whose operations can be facilitated 
    by information about their solidity or momentum in accordance with certain principles such as impetus,
  p and
  p: :t()
    this system of object indexes sometimes gives rise to phenomenal expectations concerning 
    locations or movements of objects.
   
   

